{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thekhoi/futme/RTD-ueh/env_image/bin/pip: 2: exec: /home/thekhoi/futme/RTD ueh/env_image/bin/python3: not found\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thekhoi/futme/RTD-ueh/env_image/bin/pip: 2: exec: /home/thekhoi/futme/RTD ueh/env_image/bin/python3: not found\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8s-pose.pt to 'yolov8s-pose.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22.4M/22.4M [00:02<00:00, 11.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8s-pose.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/thekhoi/futme/RTD-ueh/pose-pexels-nappy-936094.jpg: 448x640 1 person, 68.0ms\n",
      "Speed: 2.2ms preprocess, 68.0ms inference, 124.7ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(\"pose-pexels-nappy-936094.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: tensor([[0.9924, 0.6953, 0.9935, 0.0367, 0.9820, 0.9947, 0.9988, 0.9697, 0.9969, 0.9617, 0.9941, 0.9954, 0.9969, 0.9947, 0.9971, 0.9315, 0.9449]], device='cuda:0')\n",
      "data: tensor([[[1.2947e+03, 3.3744e+02, 9.9242e-01],\n",
      "         [1.3133e+03, 3.0696e+02, 6.9530e-01],\n",
      "         [1.2600e+03, 2.8535e+02, 9.9349e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 3.6736e-02],\n",
      "         [1.1403e+03, 2.4890e+02, 9.8199e-01],\n",
      "         [1.2088e+03, 4.1319e+02, 9.9466e-01],\n",
      "         [9.4450e+02, 3.1990e+02, 9.9876e-01],\n",
      "         [1.2845e+03, 7.2580e+02, 9.6975e-01],\n",
      "         [8.4975e+02, 6.7891e+02, 9.9685e-01],\n",
      "         [1.4329e+03, 9.8713e+02, 9.6170e-01],\n",
      "         [8.8343e+02, 1.0539e+03, 9.9410e-01],\n",
      "         [7.0596e+02, 3.7326e+02, 9.9540e-01],\n",
      "         [5.7241e+02, 3.2018e+02, 9.9689e-01],\n",
      "         [8.0972e+02, 7.4386e+02, 9.9472e-01],\n",
      "         [8.6008e+02, 6.3547e+02, 9.9708e-01],\n",
      "         [4.8710e+02, 9.8086e+02, 9.3155e-01],\n",
      "         [7.0966e+02, 1.0084e+03, 9.4489e-01]]], device='cuda:0')\n",
      "has_visible: True\n",
      "orig_shape: (1365, 2048)\n",
      "shape: torch.Size([1, 17, 3])\n",
      "xy: tensor([[[1294.7112,  337.4356],\n",
      "         [1313.2745,  306.9578],\n",
      "         [1260.0225,  285.3545],\n",
      "         [   0.0000,    0.0000],\n",
      "         [1140.2852,  248.8975],\n",
      "         [1208.8235,  413.1948],\n",
      "         [ 944.5031,  319.8962],\n",
      "         [1284.5005,  725.8015],\n",
      "         [ 849.7516,  678.9106],\n",
      "         [1432.8910,  987.1288],\n",
      "         [ 883.4342, 1053.9276],\n",
      "         [ 705.9577,  373.2643],\n",
      "         [ 572.4106,  320.1827],\n",
      "         [ 809.7184,  743.8608],\n",
      "         [ 860.0760,  635.4743],\n",
      "         [ 487.1011,  980.8568],\n",
      "         [ 709.6608, 1008.4422]]], device='cuda:0')\n",
      "xyn: tensor([[[0.6322, 0.2472],\n",
      "         [0.6412, 0.2249],\n",
      "         [0.6152, 0.2091],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.5568, 0.1823],\n",
      "         [0.5902, 0.3027],\n",
      "         [0.4612, 0.2344],\n",
      "         [0.6272, 0.5317],\n",
      "         [0.4149, 0.4974],\n",
      "         [0.6997, 0.7232],\n",
      "         [0.4314, 0.7721],\n",
      "         [0.3447, 0.2735],\n",
      "         [0.2795, 0.2346],\n",
      "         [0.3954, 0.5450],\n",
      "         [0.4200, 0.4655],\n",
      "         [0.2378, 0.7186],\n",
      "         [0.3465, 0.7388]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(results[0].keypoints)\n",
    "keypoints = results[0].keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9924, device='cuda:0') tensor([1294.7112,  337.4356], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "conf = keypoints.conf[0]\n",
    "xy_visible = keypoints.xy[0]\n",
    "\n",
    "print(conf[0], xy_visible[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in ./env_tmp/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.19.3 in ./env_tmp/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_visible.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _draw_edges(image, keypoints, thres = 0.2):\n",
    "    edges = [\n",
    "        (0, 1), (0, 2), (1, 3), (2, 4),\n",
    "        (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),\n",
    "        (5, 11), (6, 12), (11, 12),\n",
    "        (11, 13), (12, 14), (13, 15), (14, 16)\n",
    "    ]\n",
    "    xy = keypoints.xy[0]\n",
    "    conf = keypoints.conf[0]\n",
    "    for edge in edges:\n",
    "        if conf[edge[0]] < thres or conf[edge[1]] < thres:\n",
    "            continue\n",
    "        x1, y1 = xy[edge[0]]\n",
    "        x2, y2 = xy[edge[1]]\n",
    "        image = cv2.line(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "    return image\n",
    "def draw_skeleton(image, keypoints, thres=0.1):\n",
    "    conf = keypoints.conf[0]\n",
    "    xy = keypoints.xy[0]\n",
    "    for i in range(len(conf)):\n",
    "        if conf[i] > thres:\n",
    "            x, y = xy[i][:2]\n",
    "            print('x, y, conf:', x, y, conf[i])\n",
    "            image = cv2.circle(image, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
    "    image = _draw_edges(image, keypoints)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x, y, conf: tensor(1294.7112, device='cuda:0') tensor(337.4356, device='cuda:0') tensor(0.9924, device='cuda:0')\n",
      "x, y, conf: tensor(1313.2745, device='cuda:0') tensor(306.9578, device='cuda:0') tensor(0.6953, device='cuda:0')\n",
      "x, y, conf: tensor(1260.0225, device='cuda:0') tensor(285.3545, device='cuda:0') tensor(0.9935, device='cuda:0')\n",
      "x, y, conf: tensor(1140.2852, device='cuda:0') tensor(248.8975, device='cuda:0') tensor(0.9820, device='cuda:0')\n",
      "x, y, conf: tensor(1208.8235, device='cuda:0') tensor(413.1948, device='cuda:0') tensor(0.9947, device='cuda:0')\n",
      "x, y, conf: tensor(944.5031, device='cuda:0') tensor(319.8962, device='cuda:0') tensor(0.9988, device='cuda:0')\n",
      "x, y, conf: tensor(1284.5005, device='cuda:0') tensor(725.8015, device='cuda:0') tensor(0.9697, device='cuda:0')\n",
      "x, y, conf: tensor(849.7516, device='cuda:0') tensor(678.9106, device='cuda:0') tensor(0.9969, device='cuda:0')\n",
      "x, y, conf: tensor(1432.8910, device='cuda:0') tensor(987.1288, device='cuda:0') tensor(0.9617, device='cuda:0')\n",
      "x, y, conf: tensor(883.4342, device='cuda:0') tensor(1053.9276, device='cuda:0') tensor(0.9941, device='cuda:0')\n",
      "x, y, conf: tensor(705.9577, device='cuda:0') tensor(373.2643, device='cuda:0') tensor(0.9954, device='cuda:0')\n",
      "x, y, conf: tensor(572.4106, device='cuda:0') tensor(320.1827, device='cuda:0') tensor(0.9969, device='cuda:0')\n",
      "x, y, conf: tensor(809.7184, device='cuda:0') tensor(743.8608, device='cuda:0') tensor(0.9947, device='cuda:0')\n",
      "x, y, conf: tensor(860.0760, device='cuda:0') tensor(635.4743, device='cuda:0') tensor(0.9971, device='cuda:0')\n",
      "x, y, conf: tensor(487.1011, device='cuda:0') tensor(980.8568, device='cuda:0') tensor(0.9315, device='cuda:0')\n",
      "x, y, conf: tensor(709.6608, device='cuda:0') tensor(1008.4422, device='cuda:0') tensor(0.9449, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"pose-pexels-nappy-936094.jpg\")\n",
    "\n",
    "img = draw_skeleton(img, keypoints)\n",
    "cv2.imwrite(\"pose-pexels-nappy-936094-annotated.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
